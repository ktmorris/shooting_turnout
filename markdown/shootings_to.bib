
@article{Calonico2014,
  title = {Robust {{Nonparametric Confidence Intervals}} for {{Regression}}-{{Discontinuity Designs}}},
  author = {Calonico, Sebastian and Cattaneo, Matias D. and Titiunik, Rocio},
  date = {2014},
  journaltitle = {Econometrica},
  volume = {82},
  number = {6},
  pages = {2295--2326},
  issn = {1468-0262},
  doi = {10.3982/ECTA11757},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA11757},
  urldate = {2021-10-27},
  abstract = {In the regression-discontinuity (RD) design, units are assigned to treatment based on whether their value of an observed covariate exceeds a known cutoff. In this design, local polynomial estimators are now routinely employed to construct confidence intervals for treatment effects. The performance of these confidence intervals in applications, however, may be seriously hampered by their sensitivity to the specific bandwidth employed. Available bandwidth selectors typically yield a “large” bandwidth, leading to data-driven confidence intervals that may be biased, with empirical coverage well below their nominal target. We propose new theory-based, more robust confidence interval estimators for average treatment effects at the cutoff in sharp RD, sharp kink RD, fuzzy RD, and fuzzy kink RD designs. Our proposed confidence intervals are constructed using a bias-corrected RD estimator together with a novel standard error estimator. For practical implementation, we discuss mean squared error optimal bandwidths, which are by construction not valid for conventional confidence intervals but are valid with our robust approach, and consistent standard error estimators based on our new variance formulas. In a special case of practical interest, our procedure amounts to running a quadratic instead of a linear local regression. More generally, our results give a formal justification to simple inference procedures based on increasing the order of the local polynomial estimator employed. We find in a simulation study that our confidence intervals exhibit close-to-correct empirical coverage and good empirical interval length on average, remarkably improving upon the alternatives available in the literature. All results are readily available in R and STATA using our companion software packages described in Calonico, Cattaneo, and Titiunik (2014d, 2014b).},
  langid = {english},
  keywords = {alternative asymptotics,bias correction,local polynomials,Regression discontinuity,robust inference},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3982/ECTA11757},
  file = {C\:\\Users\\morrisk\\Zotero\\storage\\IUZZAHIV\\Calonico et al. - 2014 - Robust Nonparametric Confidence Intervals for Regr.pdf;C\:\\Users\\morrisk\\Zotero\\storage\\9DWTUQQV\\ECTA11757.html}
}

@online{Stommes2021,
  title = {On the Reliability of Published Findings Using the Regression Discontinuity Design in Political Science},
  author = {Stommes, Drew and Aronow, P. M. and Sävje, Fredrik},
  date = {2021-09-29},
  eprint = {2109.14526},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2109.14526},
  urldate = {2021-10-27},
  abstract = {The regression discontinuity (RD) design offers identification of causal effects under weak assumptions, earning it the position as a standard method in modern political science research. But identification does not necessarily imply that the causal effects can be estimated accurately with limited data. In this paper, we highlight that estimation is particularly challenging with the RD design and investigate how these challenges manifest themselves in the empirical literature. We collect all RD-based findings published in top political science journals from 2009--2018. The findings exhibit pathological features; estimates tend to bunch just above the conventional level of statistical significance. A reanalysis of all studies with available data suggests that researcher's discretion is not a major driver of these pathological features, but researchers tend to use inappropriate methods for inference, rendering standard errors artificially small. A retrospective power analysis reveals that most of these studies were underpowered to detect all but large effects. The issues we uncover, combined with well-documented selection pressures in academic publishing, cause concern that many published findings using the RD design are exaggerated, if not entirely spurious.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {C\:\\Users\\morrisk\\Zotero\\storage\\66XU8YXU\\Stommes et al. - 2021 - On the reliability of published findings using the.pdf;C\:\\Users\\morrisk\\Zotero\\storage\\UXNWEYHM\\2109.html}
}


